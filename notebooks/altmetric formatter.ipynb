{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the number of docs that have a doi or pmid (to make it easy to figure out when to stop scrolling)\n",
    "def fetch_src_size():\n",
    "    pubmeta = requests.get(\"https://api.outbreak.info/resources/query?q=((_exists_:pmid)or(_exists__:doi))\")\n",
    "    pubjson = json.loads(pubmeta.text)\n",
    "    pubcount = int(pubjson[\"total\"])\n",
    "    return(pubcount)\n",
    "\n",
    "#### Pull ids from a json file use dois whenever possible\n",
    "def get_ids_from_json(jsonfile):\n",
    "    idlist = []\n",
    "    for eachhit in jsonfile[\"hits\"]:\n",
    "        try:\n",
    "            doi = eachhit[\"doi\"]\n",
    "            if doi!= \"\":\n",
    "                idlist.append(doi)\n",
    "        except:\n",
    "            if eachhit[\"_id\"] not in idlist:\n",
    "                idlist.append(eachhit[\"_id\"])\n",
    "    return(idlist)\n",
    "\n",
    "#### Ping the API and get the ids and dois and scroll through until they're all obtained\n",
    "def get_source_ids():\n",
    "    doi_source_size = fetch_src_size()\n",
    "    r = requests.get(\"https://api.outbreak.info/resources/query?q=((_exists_:pmid)or(_exists_:doi))&fields=_id,doi&fetch_all=true\")\n",
    "    response = json.loads(r.text)\n",
    "    idlist = get_ids_from_json(response)\n",
    "    try:\n",
    "        scroll_id = response[\"_scroll_id\"]\n",
    "        while len(idlist) < source_size:\n",
    "            r2 = requests.get(\"https://api.outbreak.info/resources/query?q=((_exists_:pmid)or(_exists_:doi))&fields=_id,doi&fetch_all=true&scroll_id=\"+scroll_id)\n",
    "            response2 = json.loads(r2.text)\n",
    "            idlist2 = set(get_ids_from_json(response2))\n",
    "            tmpset = set(idlist)\n",
    "            idlist = tmpset.union(idlist2)\n",
    "            try:\n",
    "                scroll_id = response2[\"_scroll_id\"]\n",
    "            except:\n",
    "                print(\"no new scroll id\")\n",
    "            time.sleep(1)\n",
    "        return(idlist)\n",
    "    except:\n",
    "        return(idlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_curator():\n",
    "    todate = datetime.now()\n",
    "    curatedByObject = {\"@type\": \"Organization\", \"identifier\": \"altmetric\",  \n",
    "                       \"name\": \"Altmetric\", \"affiliation\": [\"Digital Science\"],\n",
    "                       \"curationDate\": todate.strftime(\"%Y-%m-%d\")}\n",
    "    return(curatedByObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Altmetrics allows you to search by pubmed id and doi's\n",
    "## Searching by Zenodo ids and figshare ids don't seem to work\n",
    "\n",
    "def clean_ids(idlist):\n",
    "    pmidlist = [ x for x in idlist if \"pmid\" in x ]\n",
    "    doilist = [ x for x in idlist if \"10.\" in x ] \n",
    "    cleanidlist = list(set(pmidlist).union(set(doilist)))\n",
    "    missinglist = [ x for x in idlist if x not in cleanidlist ] \n",
    "    return(cleanidlist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_key():\n",
    "    #cred_path = os.path.join(DATA_PATH, 'credentials.json')\n",
    "    cred_path = 'credentials.json'\n",
    "    with open(cred_path) as f:\n",
    "        credentials = json.load(f) \n",
    "        apikey = credentials[\"key\"]\n",
    "    return(apikey)\n",
    "\n",
    "\n",
    "def fetch_meta(pubid):\n",
    "    apikey = load_key()\n",
    "    base_url = 'https://api.altmetric.com/v1/'\n",
    "    key_url = '?key='+apikey\n",
    "    if 'pmid' in pubid:\n",
    "        api_call = base_url+'pmid/'+pubid.replace(\"pmid\",\"\")+key_url\n",
    "    else:\n",
    "        api_call = base_url+'doi/'+pubid+key_url\n",
    "    r = requests.get(api_call)\n",
    "    if r.status_code==200:\n",
    "        rawmeta = json.loads(r.text)\n",
    "        error=False\n",
    "    else:\n",
    "        rawmeta={}\n",
    "        error=True\n",
    "    time.sleep(0.25)\n",
    "    return(rawmeta,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dump(cleanidlist):\n",
    "    altdump = []\n",
    "    for eachid in cleanidlist:\n",
    "        aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                       'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                       'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                       'readers_count']\n",
    "        readerlist = ['citeulike','mendeley','connotea']\n",
    "        rawmeta,error = fetch_meta(eachid)\n",
    "        if error == False :\n",
    "            authorObject = generate_curator()\n",
    "            altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                       \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                       \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "            reviewlist = []\n",
    "            for eachrating in aspectslist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            for eachreader in readerlist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            altdict[\"reviews\"]=reviewlist\n",
    "            dumpdict = {\"_id\":eachid, \n",
    "                       \"evaluations\":[altdict]}\n",
    "            altdump.append(dumpdict)\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altmetrics_update():\n",
    "    print('fetching ids: ',datetime.now())\n",
    "    idlist = get_source_ids()\n",
    "    print('cleaning up ids: ',datetime.now())\n",
    "    cleanidlist = clean_ids(idlist)\n",
    "    print('fetching altmetrics: ',datetime.now())\n",
    "    altdump = generate_dump(cleanidlist)\n",
    "    print('exporting results: ',datetime.now())\n",
    "    with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_altmetric_id(id_to_check):\n",
    "    altdump = generate_dump([id_to_check])\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '10.6084/m9.figshare.12019035', 'evaluations': [{'@type': 'AggregateRating', 'author': {'@type': 'Organization', 'identifier': 'altmetric', 'name': 'Altmetric', 'affiliation': ['Digital Science'], 'curationDate': '2021-09-23'}, 'identifier': 78407432, 'url': 'http://www.altmetric.com/details.php?citation_id=78407432', 'image': 'https://badges.altmetric.com/?size=64&score=39&types=tttttttt', 'name': 'Altmetric', 'reviewAspect': 'Altmetric score', 'ratingValue': 38.8, 'reviews': [{'@type': 'Review', 'reviewAspect': 'cited_by_fbwalls_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_feeds_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_gplus_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_msm_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_posts_count', 'reviewRating': {'ratingValue': 44}}, {'@type': 'Review', 'reviewAspect': 'cited_by_rdts_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_tweeters_count', 'reviewRating': {'ratingValue': 43}}, {'@type': 'Review', 'reviewAspect': 'cited_by_videos_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'cited_by_accounts_count', 'reviewRating': {'ratingValue': 43}}, {'@type': 'Review', 'reviewAspect': 'readers_count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'citeulike reader count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'mendeley reader count', 'reviewRating': {'ratingValue': 0}}, {'@type': 'Review', 'reviewAspect': 'connotea reader count', 'reviewRating': {'ratingValue': 0}}]}]}]\n"
     ]
    }
   ],
   "source": [
    "altdump = check_altmetric_id(\"10.6084/m9.figshare.12019035\")\n",
    "print(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching ids:  2021-07-16 22:35:35.961395\n",
      "cleaning up ids:  2021-07-16 22:40:52.198848\n",
      "fetching altmetrics:  2021-07-16 22:54:57.800586\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e5e26581ff82>\u001b[0m in \u001b[0;36mgenerate_dump\u001b[1;34m(cleanidlist)\u001b[0m\n\u001b[0;32m      7\u001b[0m                        'readers_count']\n\u001b[0;32m      8\u001b[0m         \u001b[0mreaderlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'citeulike'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mendeley'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'connotea'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mrawmeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meachid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mauthorObject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_curator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8057ffa3d9ec>\u001b[0m in \u001b[0;36mfetch_meta\u001b[1;34m(pubid)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mrawmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawmeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('fetching ids: ',datetime.now())\n",
    "idlist = get_source_ids()\n",
    "print('cleaning up ids: ',datetime.now())\n",
    "cleanidlist = clean_ids(idlist)\n",
    "print('fetching altmetrics: ',datetime.now())\n",
    "altdump = generate_dump(cleanidlist)\n",
    "print('exporting results: ',datetime.now())\n",
    "with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_altmetrics_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170441\n"
     ]
    }
   ],
   "source": [
    "print(len(cleanidlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bc1aeea43e4fd59d8d20c65a93a565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 1d 15min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#print('fetching ids: ',datetime.now())\n",
    "#idlist = get_source_ids()\n",
    "#print('cleaning up ids: ',datetime.now())\n",
    "#cleanidlist = clean_ids(idlist)\n",
    "#print('fetching altmetrics: ',datetime.now())\n",
    "\n",
    "#altdump = []\n",
    "for i in tqdm(range(48613,170953)):\n",
    "    eachid = cleanidlist[i]\n",
    "    aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                   'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                   'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                   'readers_count']\n",
    "    readerlist = ['citeulike','mendeley','connotea']\n",
    "    rawmeta,error = fetch_meta(eachid)\n",
    "    if error == False :\n",
    "        authorObject = generate_curator()\n",
    "        altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                   \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                   \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "        reviewlist = []\n",
    "        for eachrating in aspectslist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        for eachreader in readerlist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        altdict[\"reviews\"]=reviewlist\n",
    "        dumpdict = {\"_id\":eachid, \n",
    "                   \"evaluations\":[altdict]}\n",
    "        altdump.append(dumpdict)\n",
    "with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
