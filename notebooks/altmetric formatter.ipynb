{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set time out and max retries\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "DEFAULT_TIMEOUT = 5 # seconds\n",
    "\n",
    "class TimeoutHTTPAdapter(HTTPAdapter):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.timeout = DEFAULT_TIMEOUT\n",
    "        if \"timeout\" in kwargs:\n",
    "            self.timeout = kwargs[\"timeout\"]\n",
    "            del kwargs[\"timeout\"]\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def send(self, request, **kwargs):\n",
    "        timeout = kwargs.get(\"timeout\")\n",
    "        if timeout is None:\n",
    "            kwargs[\"timeout\"] = self.timeout\n",
    "        return super().send(request, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the number of docs that have a doi or pmid (to make it easy to figure out when to stop scrolling)\n",
    "\n",
    "query_types = {\"pubs\":'((_exists_:pmid)or(_exists__:doi))',\n",
    "               \"clins\":'(curatedBy.name:\"ClinicalTrials.gov\")'}\n",
    "\n",
    "def fetch_src_size(query_type):\n",
    "    pubmeta = httprequests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type)\n",
    "    pubjson = json.loads(pubmeta.text)\n",
    "    pubcount = int(pubjson[\"total\"])\n",
    "    return(pubcount)\n",
    "\n",
    "#### Pull ids from a json file use dois whenever possible\n",
    "def get_ids_from_json(jsonfile):\n",
    "    idlist = []\n",
    "    for eachhit in jsonfile[\"hits\"]:\n",
    "        try:\n",
    "            doi = eachhit[\"doi\"]\n",
    "            if doi!= \"\":\n",
    "                idlist.append(doi)\n",
    "        except:\n",
    "            if eachhit[\"_id\"] not in idlist:\n",
    "                idlist.append(eachhit[\"_id\"])\n",
    "    return(idlist)\n",
    "\n",
    "#### Ping the API and get the ids and dois and scroll through until they're all obtained\n",
    "def get_source_ids(query_type):\n",
    "    source_size = fetch_src_size(query_type)\n",
    "    r = httprequests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type+\"&fields=_id,doi&fetch_all=true\")\n",
    "    response = json.loads(r.text)\n",
    "    idlist = get_ids_from_json(response)\n",
    "    try:\n",
    "        scroll_id = response[\"_scroll_id\"]\n",
    "        while len(idlist) < source_size:\n",
    "            r2 = httprequests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type+\"&fields=_id,doi&fetch_all=true&scroll_id=\"+scroll_id)\n",
    "            response2 = json.loads(r2.text)\n",
    "            idlist2 = set(get_ids_from_json(response2))\n",
    "            tmpset = set(idlist)\n",
    "            idlist = tmpset.union(idlist2)\n",
    "            try:\n",
    "                scroll_id = response2[\"_scroll_id\"]\n",
    "            except:\n",
    "                print(\"no new scroll id\")\n",
    "            time.sleep(1)\n",
    "        return(idlist)\n",
    "    except:\n",
    "        return(idlist)\n",
    "\n",
    "def map_to_main_id(eachid):\n",
    "    try:\n",
    "        r = httprequests.get('https://api.outbreak.info/resources/query?q=doi:\"'+eachid+'\"')\n",
    "        response = json.loads(r.text)\n",
    "        outbreak_id = response['hits'][0]['_id']\n",
    "    except:\n",
    "        outbreak_id = eachid\n",
    "    return(outbreak_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_curator():\n",
    "    todate = datetime.now()\n",
    "    curatedByObject = {\"@type\": \"Organization\", \"identifier\": \"altmetric\",  \n",
    "                       \"name\": \"Altmetric\", \"affiliation\": [\"Digital Science\"],\n",
    "                       \"curationDate\": todate.strftime(\"%Y-%m-%d\")}\n",
    "    return(curatedByObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Altmetrics allows you to search by pubmed id, nct id, and doi's\n",
    "## Searching by Zenodo ids and figshare ids don't seem to work\n",
    "## Remove any ids that are not of these types\n",
    "\n",
    "def clean_ids(idlist):\n",
    "    pmidlist = [ x for x in idlist if \"pmid\" in x ]\n",
    "    doilist = [ x for x in idlist if \"10.\" in x ] \n",
    "    nctlist = [ x for x in idlist if \"NCT\" in x ]\n",
    "    cleanidlist = list(set(pmidlist).union(set(doilist).union(set(nctlist))))\n",
    "    #missinglist = [ x for x in idlist if x not in cleanidlist ] ##(only for checking incompatible ids)\n",
    "    return(cleanidlist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_key(script_path):\n",
    "    cred_path = os.path.join(script_path, 'credentials.json')\n",
    "    with open(cred_path) as f:\n",
    "        credentials = json.load(f) \n",
    "        apikey = credentials[\"key\"]\n",
    "    return(apikey)\n",
    "\n",
    "\n",
    "def fetch_meta(key_url,pubid):\n",
    "    base_url = 'https://api.altmetric.com/v1/'\n",
    "    if 'pmid' in pubid:\n",
    "        api_call = base_url+'pmid/'+pubid.replace(\"pmid\",\"\")+key_url\n",
    "    elif 'NCT' in pubid:\n",
    "        api_call = base_url+'nct_id/'+pubid+key_url       \n",
    "    else:\n",
    "        api_call = base_url+'doi/'+pubid+key_url\n",
    "    r = httprequests.get(api_call)\n",
    "    try:\n",
    "        hourlylimit = r.headers[\"X-HourlyRateLimit-Limit\"]\n",
    "        secondslimit = int(hourlylimit)/3600\n",
    "        sleeptime = 1/secondslimit\n",
    "    except:\n",
    "        sleeptime = 1\n",
    "    if r.status_code==200:\n",
    "        rawmeta = json.loads(r.text)\n",
    "        error=False\n",
    "    else:\n",
    "        rawmeta={}\n",
    "        error=True\n",
    "    return(rawmeta,error,sleeptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dump(script_path,cleanidlist):\n",
    "    apikey = load_key(script_path)\n",
    "    key_url = '?key='+apikey\n",
    "    altdump = []\n",
    "    for eachid in cleanidlist:\n",
    "        aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                       'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                       'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                       'readers_count']\n",
    "        readerlist = ['citeulike','mendeley','connotea']\n",
    "        rawmeta,error,sleeptime = fetch_meta(key_url,eachid)\n",
    "        if error == False :\n",
    "            authorObject = generate_curator()\n",
    "            altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                       \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                       \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "            reviewlist = []\n",
    "            for eachrating in aspectslist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            for eachreader in readerlist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            altdict[\"reviews\"]=reviewlist\n",
    "            outbreak_id = map_to_main_id(eachid)\n",
    "            dumpdict = {\"_id\":outbreak_id, \n",
    "                       \"evaluations\":[altdict]}\n",
    "            altdump.append(dumpdict)\n",
    "        time.sleep(sleeptime)\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altmetrics_update(script_path,test=False):\n",
    "    RESULTSPATH = os.path.join(script_path,'results/')\n",
    "    result_data_file = os.path.join(RESULTSPATH,'altmetric_annotations.json')\n",
    "    print('fetching ids: ',datetime.now())\n",
    "    if test == True:\n",
    "        pubidlist = [\"pmid32835433\",\"pmid32835716\",\"2020.01.19.911669\",\"2020.01.21.914929\",\"zenodo.3976542\"]\n",
    "        clinidlist = [\"NCT03348670\",\"NCT00173459\",\"NCT00571389\"]\n",
    "    else:\n",
    "        pubidlist = get_source_ids(query_types[\"pubs\"])\n",
    "        clinidlist = get_source_ids(query_types[\"clins\"])\n",
    "    idlist = list(set(pubidlist).union(set(clinidlist)))\n",
    "    print('cleaning up ids: ',datetime.now())\n",
    "    cleanidlist = clean_ids(idlist)\n",
    "    print('fetching altmetrics: ',datetime.now())\n",
    "    if test == True:\n",
    "        testidlist = random.sample(cleanidlist, 5)\n",
    "        altdump = generate_dump(script_path,testidlist)\n",
    "    else:\n",
    "        altdump = generate_dump(script_path,cleanidlist)\n",
    "    print('exporting results: ',datetime.now())\n",
    "    with open(result_data_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_altmetric_id(script_path,id_to_check):\n",
    "    altdump = generate_dump(script_path,[id_to_check])\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching ids:  2021-11-24 09:10:44.022507\n",
      "cleaning up ids:  2021-11-24 09:10:44.023504\n",
      "fetching altmetrics:  2021-11-24 09:10:44.023504\n",
      "exporting results:  2021-11-24 09:10:52.006817\n",
      "Wall time: 7.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "script_path = \"\"\n",
    "result_data_file = 'results/altmetric_annotations.json'\n",
    "\n",
    "httprequests = requests.Session()\n",
    "\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    #method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    ")\n",
    "\n",
    "# Mount it for both http and https usage\n",
    "adapter = TimeoutHTTPAdapter(timeout=2.5,max_retries=retry_strategy)\n",
    "httprequests.mount(\"https://\", adapter)\n",
    "httprequests.mount(\"http://\", adapter)\n",
    "\n",
    "get_altmetrics_update(script_path,test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = \"\"\n",
    "altdump = check_altmetric_id(script_path,\"10.6084/m9.figshare.12019035\")\n",
    "print(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "script_path = \"\"\n",
    "get_altmetrics_update(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#print('fetching ids: ',datetime.now())\n",
    "#pubidlist = get_source_ids(query_types[\"pubs\"])\n",
    "#print(len(pubidlist))\n",
    "#clinidlist = get_source_ids(query_types[\"clins\"])\n",
    "#print(len(clinidlist))\n",
    "#idlist = list(set(pubidlist).union(set(clinidlist)))\n",
    "#print('cleaning up ids: ',datetime.now())\n",
    "#cleanidlist = clean_ids(idlist)\n",
    "print('fetching altmetrics: ',datetime.now())\n",
    "\n",
    "#altdump = []\n",
    "for i in tqdm(range(158478,191240)):\n",
    "    eachid = cleanidlist[i]\n",
    "    aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                   'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                   'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                   'readers_count']\n",
    "    readerlist = ['citeulike','mendeley','connotea']\n",
    "    rawmeta,error = fetch_meta(eachid)\n",
    "    if error == False :\n",
    "        authorObject = generate_curator()\n",
    "        altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                   \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                   \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "        reviewlist = []\n",
    "        for eachrating in aspectslist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        for eachreader in readerlist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        altdict[\"reviews\"]=reviewlist\n",
    "        dumpdict = {\"_id\":eachid, \n",
    "                   \"evaluations\":[altdict]}\n",
    "        altdump.append(dumpdict)\n",
    "    time.sleep(1)\n",
    "with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
