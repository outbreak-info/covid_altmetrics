{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the number of docs that have a doi or pmid (to make it easy to figure out when to stop scrolling)\n",
    "\n",
    "query_types = {\"pubs\":'((_exists_:pmid)or(_exists__:doi))',\n",
    "               \"clins\":'(curatedBy.name:\"ClinicalTrials.gov\")'}\n",
    "\n",
    "def fetch_src_size(query_type):\n",
    "    pubmeta = requests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type)\n",
    "    pubjson = json.loads(pubmeta.text)\n",
    "    pubcount = int(pubjson[\"total\"])\n",
    "    return(pubcount)\n",
    "\n",
    "#### Pull ids from a json file use dois whenever possible\n",
    "def get_ids_from_json(jsonfile):\n",
    "    idlist = []\n",
    "    for eachhit in jsonfile[\"hits\"]:\n",
    "        try:\n",
    "            doi = eachhit[\"doi\"]\n",
    "            if doi!= \"\":\n",
    "                idlist.append(doi)\n",
    "        except:\n",
    "            if eachhit[\"_id\"] not in idlist:\n",
    "                idlist.append(eachhit[\"_id\"])\n",
    "    return(idlist)\n",
    "\n",
    "#### Ping the API and get the ids and dois and scroll through until they're all obtained\n",
    "def get_source_ids(query_type):\n",
    "    source_size = fetch_src_size(query_type)\n",
    "    r = requests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type+\"&fields=_id,doi&fetch_all=true\")\n",
    "    response = json.loads(r.text)\n",
    "    idlist = get_ids_from_json(response)\n",
    "    try:\n",
    "        scroll_id = response[\"_scroll_id\"]\n",
    "        while len(idlist) < source_size:\n",
    "            r2 = requests.get(\"https://api.outbreak.info/resources/query?q=\"+query_type+\"&fields=_id,doi&fetch_all=true&scroll_id=\"+scroll_id)\n",
    "            response2 = json.loads(r2.text)\n",
    "            idlist2 = set(get_ids_from_json(response2))\n",
    "            tmpset = set(idlist)\n",
    "            idlist = tmpset.union(idlist2)\n",
    "            try:\n",
    "                scroll_id = response2[\"_scroll_id\"]\n",
    "            except:\n",
    "                print(\"no new scroll id\")\n",
    "            time.sleep(1)\n",
    "        return(idlist)\n",
    "    except:\n",
    "        return(idlist)\n",
    "\n",
    "def map_to_main_id(eachid):\n",
    "    try:\n",
    "        r = requests.get('https://api.outbreak.info/resources/query?q=doi:\"'+eachid+'\"')\n",
    "        response = json.loads(r.text)\n",
    "        outbreak_id = response['hits'][0]['_id']\n",
    "    except:\n",
    "        outbreak_id = eachid\n",
    "    return(outbreak_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_curator():\n",
    "    todate = datetime.now()\n",
    "    curatedByObject = {\"@type\": \"Organization\", \"identifier\": \"altmetric\",  \n",
    "                       \"name\": \"Altmetric\", \"affiliation\": [\"Digital Science\"],\n",
    "                       \"curationDate\": todate.strftime(\"%Y-%m-%d\")}\n",
    "    return(curatedByObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Altmetrics allows you to search by pubmed id, nct id, and doi's\n",
    "## Searching by Zenodo ids and figshare ids don't seem to work\n",
    "## Remove any ids that are not of these types\n",
    "\n",
    "def clean_ids(idlist):\n",
    "    pmidlist = [ x for x in idlist if \"pmid\" in x ]\n",
    "    doilist = [ x for x in idlist if \"10.\" in x ] \n",
    "    nctlist = [ x for x in idlist if \"NCT\" in x ]\n",
    "    cleanidlist = list(set(pmidlist).union(set(doilist).union(set(nctlist))))\n",
    "    missinglist = [ x for x in idlist if x not in cleanidlist ] \n",
    "    return(cleanidlist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_key():\n",
    "    #cred_path = os.path.join(DATA_PATH, 'credentials.json')\n",
    "    cred_path = 'credentials.json'\n",
    "    with open(cred_path) as f:\n",
    "        credentials = json.load(f) \n",
    "        apikey = credentials[\"key\"]\n",
    "    return(apikey)\n",
    "\n",
    "\n",
    "def fetch_meta(pubid):\n",
    "    apikey = load_key()\n",
    "    base_url = 'https://api.altmetric.com/v1/'\n",
    "    key_url = '?key='+apikey\n",
    "    if 'pmid' in pubid:\n",
    "        api_call = base_url+'pmid/'+pubid.replace(\"pmid\",\"\")+key_url\n",
    "    elif 'NCT' in pubid:\n",
    "        api_call = base_url+'nct_id/'+pubid+key_url       \n",
    "    else:\n",
    "        api_call = base_url+'doi/'+pubid+key_url\n",
    "    r = requests.get(api_call)\n",
    "    if r.status_code==200:\n",
    "        rawmeta = json.loads(r.text)\n",
    "        error=False\n",
    "    else:\n",
    "        rawmeta={}\n",
    "        error=True\n",
    "    return(rawmeta,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dump(cleanidlist):\n",
    "    altdump = []\n",
    "    for eachid in cleanidlist:\n",
    "        aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                       'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                       'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                       'readers_count']\n",
    "        readerlist = ['citeulike','mendeley','connotea']\n",
    "        rawmeta,error = fetch_meta(eachid)\n",
    "        if error == False :\n",
    "            authorObject = generate_curator()\n",
    "            altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                       \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                       \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "            reviewlist = []\n",
    "            for eachrating in aspectslist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            for eachreader in readerlist:\n",
    "                a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "                try:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "                except:\n",
    "                    a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "                reviewlist.append(a_review)\n",
    "            altdict[\"reviews\"]=reviewlist\n",
    "            outbreak_id = map_to_main_id(eachid)\n",
    "            dumpdict = {\"_id\":outbreak_id, \n",
    "                       \"evaluations\":[altdict]}\n",
    "            altdump.append(dumpdict)\n",
    "        time.sleep(1)\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altmetrics_update(result_data_file):\n",
    "    print('fetching ids: ',datetime.now())\n",
    "    pubidlist = get_source_ids(query_types[\"pubs\"])\n",
    "    clinidlist = get_source_ids(query_types[\"clins\"])\n",
    "    idlist = list(set(pubidlist).union(set(clinidlist)))\n",
    "    print('cleaning up ids: ',datetime.now())\n",
    "    cleanidlist = clean_ids(idlist)\n",
    "    print('fetching altmetrics: ',datetime.now())\n",
    "    altdump = generate_dump(cleanidlist)\n",
    "    print('exporting results: ',datetime.now())\n",
    "    with open(result_data_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_altmetric_id(id_to_check):\n",
    "    altdump = generate_dump([id_to_check])\n",
    "    return(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altdump = check_altmetric_id(\"10.6084/m9.figshare.12019035\")\n",
    "print(altdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('fetching ids: ',datetime.now())\n",
    "pubidlist = get_source_ids(query_types[\"pubs\"])\n",
    "print(len(pubidlist))\n",
    "clinidlist = get_source_ids(query_types[\"clins\"])\n",
    "print(len(clinidlist))\n",
    "idlist = list(set(pubidlist).union(set(clinidlist)))\n",
    "print('cleaning up ids: ',datetime.now())\n",
    "cleanidlist = clean_ids(idlist)\n",
    "print('fetching altmetrics: ',datetime.now())\n",
    "altdump = generate_dump(cleanidlist)\n",
    "print('exporting results: ',datetime.now())\n",
    "with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_data_file = 'results/altmetric_annotations.json'\n",
    "get_altmetrics_update(result_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cleanidlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('fetching ids: ',datetime.now())\n",
    "idlist = get_source_ids()\n",
    "print('cleaning up ids: ',datetime.now())\n",
    "cleanidlist = clean_ids(idlist)\n",
    "print('fetching altmetrics: ',datetime.now())\n",
    "\n",
    "altdump = []\n",
    "for i in tqdm(range(len(cleanidlist))):\n",
    "    eachid = cleanidlist[i]\n",
    "    aspectslist = ['cited_by_fbwalls_count','cited_by_feeds_count','cited_by_gplus_count',\n",
    "                   'cited_by_msm_count','cited_by_posts_count','cited_by_rdts_count',\n",
    "                   'cited_by_tweeters_count','cited_by_videos_count','cited_by_accounts_count',\n",
    "                   'readers_count']\n",
    "    readerlist = ['citeulike','mendeley','connotea']\n",
    "    rawmeta,error = fetch_meta(eachid)\n",
    "    if error == False :\n",
    "        authorObject = generate_curator()\n",
    "        altdict = {\"@type\":\"AggregateRating\", \"author\":authorObject, \"identifier\":rawmeta[\"altmetric_id\"],\n",
    "                   \"url\":rawmeta[\"details_url\"], \"image\":rawmeta[\"images\"][\"small\"], \"name\":\"Altmetric\",\n",
    "                   \"reviewAspect\":\"Altmetric score\", \"ratingValue\":rawmeta[\"score\"]}\n",
    "        reviewlist = []\n",
    "        for eachrating in aspectslist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachrating}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[eachrating]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        for eachreader in readerlist:\n",
    "            a_review = {\"@type\":\"Review\",\"reviewAspect\":eachreader+\" reader count\"}\n",
    "            try:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":rawmeta[\"readers\"][eachreader]}\n",
    "            except:\n",
    "                a_review[\"reviewRating\"]={\"ratingValue\":0}\n",
    "            reviewlist.append(a_review)\n",
    "        altdict[\"reviews\"]=reviewlist\n",
    "        dumpdict = {\"_id\":eachid, \n",
    "                   \"evaluations\":[altdict]}\n",
    "        altdump.append(dumpdict)\n",
    "    time.sleep(1)\n",
    "with open('results/altmetric_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(altdump, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
